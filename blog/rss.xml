<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Carlos Angulo Posts</title>
        <link>https://cangulo.github.io/blog</link>
        <description>Here you can the general publications I do regarding different subjects as devops or programming 🙂</description>
        <lastBuildDate>Sun, 09 Apr 2023 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[AWS Control Tower - One year using it]]></title>
            <link>https://cangulo.github.io/blog/aws/control-tower/4-one-year-after</link>
            <guid>/aws/control-tower/4-one-year-after</guid>
            <pubDate>Sun, 09 Apr 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post I'm going to talk about my experience with Control Tower Account Factory for Terraform.]]></description>
            <content:encoded><![CDATA[<p>:::info
In this post I&#x27;m going to talk about my experience with Control Tower Account Factory for Terraform.
:::</p><h2>Summary</h2><p><a href="https://developer.hashicorp.com/terraform/tutorials/aws/aws-control-tower-aft#review-aft-components-and-workflow">Control Tower Account Factory for Terraform</a> is solution aiming to facilitate account creation and governance. You can use it to define what out-of-the-box resources your accounts will have, as well as, add new resources to all the enrolled accounts. It is based on the next workflow:</p><pre><code class="language-mermaid">graph LR
  account_request[Account Creation Request]
  global_cus[Apply Global Customization]
  spec_cus[Apply Account Customization]
  account_request--&gt;global_cus
  global_cus--&gt;spec_cus
</code></pre><i><div label="(simplified) Full schema here" link="https://developer.hashicorp.com/terraform/tutorials/aws/aws-control-tower-aft#review-aft-components-and-workflow"></div></i><p>Let&#x27;s say we want to create an account, here is an example:</p><pre><code class="language-hcl">module &quot;arepabank&quot; {
  source = &quot;./modules/aft-account-request&quot;

  control_tower_parameters = {
    AccountEmail              = &quot;arepabank-dev-aa50424c@outlook.com&quot;
    AccountName               = &quot;arepabank-dev&quot;
  }

  custom_fields                = {
    client        = &quot;arepa&quot;
    env           = &quot;dev&quot;
  }
  account_customizations_name  = &quot;dev&quot;  # you can use this to group account by stage or client
}
</code></pre><p>Then, depending what you have in the global customization repo (example <a href="https://github.com/hashicorp/learn-terraform-aft-global-customizations">here</a>) you can define resources to be created in ALL the accounts. A use case is to define a role in all the accounts (deployment role), this one can only be assumed by one IAM user (deployment user).</p><pre><code class="language-hcl" metastring="file=./resources/3/global-customizations/iam.roles.tf" file="./resources/3/global-customizations/iam.roles.tf"></code></pre><i><div label="Terraform Code in the Global Customization" link="posts/aws/control-tower/resources/3/global-customizations/iam.roles.tf"></div></i><p>Based on the account customization repository (example <a href="https://github.com/hashicorp/learn-terraform-aft-account-customizations">here</a>) and folder named as the <code>account_customizations_name</code> parameter, only the resources defined there will be created. We can use this to create different resources per stage, for example different ec2 instances:</p><pre><code class="language-bash">dev/
  ec2.micro.tf
tst/
  ec2.small.tf
acc/
  ec2.medium.tf
prd/
  ec2.large.tf
</code></pre><p>Each ec2.*.tf file will contain different configuration. </p><pre><code class="language-hcl">resource &quot;aws_instance&quot; &quot;web&quot; {
  ami           = data.aws_ami.ubuntu.id
  instance_type = &quot;t3.micro&quot;
}
</code></pre><i><div label="ec2.t3.micro.tf"></div></i><h2>Is it worth it?</h2><p>For personal projects and ephemeral workloads: No. Let me list the reasons</p><ul><li>There are fixed costs, no matter if you enroll accounts or not. Next are the main ones:<ul><li>VPC Endpoints. In my first two post I had to fork the official repo and add flags to disable them.</li><li>KMS keys. I also tried to disable it but major changes were required because it was highly coupled with other resources. </li><li>Log Archive account costs: Only S3, KMS and AWS Config services. Less than the previous two, 4$ maximum. </li></ul></li><li>AWS CodePipelines, CodeBuild and VPC costs are too high for personal projects. There is a <code>customizations-pipeline</code> for each account. This means if you want to update all accounts, all pipelines should be executed. I had 12 accounts enrolled and I paid more than 60$ one month. The same work done in the pipelines could be in GitHub workflows as I did in my <a href="./3-replacing-aws-codepipeline.mdx">previous post</a></li></ul><p><img src="resources/3/aws-costs-worst-months.png" alt="AWS Costs - worst months "/></p><p>For my personal projects I&#x27;m going to look for a custom solution with cost based on usage. </p><h2>References:</h2><ul><li><a href="https://docs.aws.amazon.com/controltower/latest/userguide/getting-started-with-control-tower.html">Starting with Control Tower</a></li><li><a href="https://docs.aws.amazon.com/controltower/latest/userguide/guardrails.html">control tower user guide</a></li></ul><h3>Git Repositories</h3>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Control Tower - Replacing CodePipelines]]></title>
            <link>https://cangulo.github.io/blog/aws/control-tower/3-replacing-aws-codepipeline</link>
            <guid>/aws/control-tower/3-replacing-aws-codepipeline</guid>
            <pubDate>Sat, 08 Apr 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post I'm going to explain how I migrate the Control Tower AFT CodePipelines to GitHub workflows.]]></description>
            <content:encoded><![CDATA[<p>:::info
In this post I&#x27;m going to explain how I migrate the Control Tower AFT CodePipelines to GitHub workflows.
:::</p><h2>wait, why?</h2><p>Simply, saving costs. Next are the monthly costs for updating 12 AWS accounts. </p><p><img src="resources/3/codepipeline-costs.png" alt="AWS Costs - worst months"/></p><table><thead><tr><th>Service</th><th>Service total</th><th>December 2022</th><th>January 2023</th></tr></thead><tbody><tr><td>VPC costs</td><td>$31.86</td><td>$30.36</td><td>$1.50</td></tr><tr><td>CodePipeline costs</td><td>$12.00</td><td>$2.00</td><td>$10.00</td></tr><tr><td>Key Management Service costs</td><td>$11.98</td><td>$5.99</td><td>$5.99</td></tr><tr><td>CodeBuild costs</td><td>$5.49</td><td>$3.54</td><td>$1.95</td></tr></tbody></table><ul><li>VPC Costs: I described in my previous post how to reduce it through a custom flag.</li><li>Code Pipeline and Codebuild costs: The main cost here is related to pipelines executions. We will dive into in the next section.</li><li>KMS: Control Tower for AFT Cost for using the secrets created with Control Tower AFT</li></ul><h3>Pipelines</h3><p>Account customization has two type: </p><ul><li>aft-global-customization in the repository <a href="https://github.com/hashicorp/learn-terraform-aft-account-customizations">learn-terraform-aft-account-customizations</a>  </li><li>aft-account-customization in the repository <a href="https://github.com/hashicorp/learn-terraform-aft-global-customizations">learn-terraform-aft-global-customizations</a>  </li></ul><p>Both are in the same CodePipeline model <code>{ACCOUNT_ID}-customizations-pipeline</code>:</p><p><img src="resources/3/codepipeline-example.png" alt="AWS Costs - example "/></p><p>There is one pipeline replica for each AWS account:</p><p><img src="resources/3/codepipeline-list.png" alt="AWS Costs - list "/></p><p>So, for updating all the accounts, all the pipelines should be executed. </p><h3>Migrating to GH workflows</h3><p>Let me first set the scope: I want to reduce the CodePipeline cost by executing GH workflows instead. </p><p>My initial approach is to create GH workflows in the <code>global-customization</code> and <code>account-customization</code> repositories to apply customizations to any account. This will work for created account, but if I create a new one that will still go through the CodePipeline. </p><p>Okey, let&#x27;s start:</p><p>First, let me list the pipelines specs:</p><ul><li><a href="https://github.com/aws-ia/terraform-aws-control_tower_account_factory/blob/60ee77b6a90e4bc6a96a60c8d8105d71ba5d3543/modules/aft-customizations/buildspecs/aft-account-customizations-terraform.yml">aft-account-customizations</a></li><li><a href="https://github.com/aws-ia/terraform-aws-control_tower_account_factory/blob/60ee77b6a90e4bc6a96a60c8d8105d71ba5d3543/modules/aft-customizations/buildspecs/aft-global-customizations-terraform.yml">aft-global-customizations</a></li></ul><p>Both share a common structure:</p><ul><li><a href="https://github.com/aws-ia/terraform-aws-control_tower_account_factory/blob/60ee77b6a90e4bc6a96a60c8d8105d71ba5d3543/modules/aft-customizations/buildspecs/aft-global-customizations-terraform.yml#L7">install</a>: setup the environment variables for the execution and install the dependencies</li><li><a href="https://github.com/aws-ia/terraform-aws-control_tower_account_factory/blob/60ee77b6a90e4bc6a96a60c8d8105d71ba5d3543/modules/aft-customizations/buildspecs/aft-global-customizations-terraform.yml#L63">pre_build</a>: execute a python script</li><li><a href="https://github.com/aws-ia/terraform-aws-control_tower_account_factory/blob/60ee77b6a90e4bc6a96a60c8d8105d71ba5d3543/modules/aft-customizations/buildspecs/aft-global-customizations-terraform.yml#L71">build</a>:  <ul><li>build <code>backend.tf</code> and <code>aft-providers.tf</code> from the templates <code>backend.jinja</code> and <code>aft-providers.jinja</code>. jinja is language that combined with python simplify files templates filling, in this case, help us build those terraform files dynamically for each account.</li><li>terraform init</li><li>terraform apply</li></ul></li><li><a href="https://github.com/aws-ia/terraform-aws-control_tower_account_factory/blob/60ee77b6a90e4bc6a96a60c8d8105d71ba5d3543/modules/aft-customizations/buildspecs/aft-global-customizations-terraform.yml#L115">post_build</a>: execute a python script, useful for a post clean up actions</li></ul><p>In order to keep it simple, I&#x27;m going to skip the pre_build and post_build part. Let&#x27;s start:</p><p>First, I want to map all the accounts detail into JSON files as:</p><p>accounts/arepabank-dev.json</p><pre><code class="language-json">{
    &quot;account_id&quot;: &quot;114628476372&quot;,
    &quot;env&quot;: &quot;dev&quot;
}
</code></pre><p>If we list those files and provide the to the <code>strategy.matrix</code> we can update multiple accounts at the same time. </p><p>Next is the main workflow code:</p><pre><code class="language-yml" metastring="file=./resources/3/global-customizations/.github/workflows/shared-tf-plan.yml" file="./resources/3/global-customizations/.github/workflows/shared-tf-plan.yml"></code></pre><p>The python code to build the .jinja file is:</p><pre><code class="language-yml" metastring="file=./resources/3/global-customizations/scripts/backend-builder.py" file="./resources/3/global-customizations/scripts/backend-builder.py"></code></pre><p>You can check the other workflows and scripts to see how I integrated this in a PR workflow:</p><ul><li><a href="./resources/3/global-customizations/.github/workflows/1-pr.yml">1-pr.yml</a></li><li><a href="./resources/3/global-customizations/.github/workflows/2-deploy-main.yml">2-deploy-main.yml</a></li><li><a href="./resources/3/global-customizations/.github/workflows/shared-tf-plan.yml">shared-tf-plan.yml</a></li><li><a href="./resources/3/global-customizations/.github/workflows/shared-get-workspaces.yml">shared-get-workspaces.yml</a></li><li><a href="./resources/3/global-customizations/scripts/backend-builder.py">backend-builder.py</a></li><li><a href="./resources/3/global-customizations/scripts/aft-providers-builder.py">aft-providers-builder.py</a></li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Control Tower - Reducing Cost 2]]></title>
            <link>https://cangulo.github.io/blog/aws/control-tower/2-disable-config-in-aft-account</link>
            <guid>/aws/control-tower/2-disable-config-in-aft-account</guid>
            <pubDate>Fri, 22 Apr 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post I'm going to talk about the costs I faced using AWS Control Tower the latest 3 months. I recommend you read my previous post before continuing. Basic knowledge about AWS Control Tower is required.]]></description>
            <content:encoded><![CDATA[<p>:::info
In this post I&#x27;m going to talk about the costs I faced using AWS Control Tower the latest 3 months. I recommend you read my <a href="./1-delete-vpc-endpoints-and-nat.mdx">previous post</a> before continuing. Basic knowledge about AWS Control Tower is required.
:::</p><h2>Latest 3 months costs:</h2><p>Before I proceed, I have to mention my usage of AFT:</p><ul><li>I only used it during January and February. I created 5 AWS Accounts.</li><li>On March I didn&#x27;t create or enroll any account. </li></ul><p>And here we have the costs:</p><p><img src="resources/2/costs-latest-3-months.png" alt="latest 3 months costs"/></p><table><thead><tr><th>Service</th><th align="right">Config($)</th><th align="right">VPC($)</th><th align="right">Tax($)</th><th align="right">EC2-Other($)</th><th align="right">CodeBuild($)</th><th align="right">KMS($)</th><th align="right">Lambda($)</th><th align="right">S3($)</th><th align="right">DynamoDB($)</th><th align="right">Backup($)</th><th align="right">EC2-Instances($)</th><th align="right">CloudWatch($)</th><th align="right">Total cost ($)</th></tr></thead><tbody><tr><td>January</td><td align="right">16.58</td><td align="right">17.34</td><td align="right">10.62</td><td align="right">8.41</td><td align="right">6.62</td><td align="right">1.56</td><td align="right">0.09</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">61.2</td></tr><tr><td>February</td><td align="right">13.9</td><td align="right">12.5</td><td align="right">10.98</td><td align="right">9.04</td><td align="right">8.5</td><td align="right">1.87</td><td align="right">6.44</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">63.22</td></tr><tr><td>March</td><td align="right">9.03</td><td align="right">0</td><td align="right">4.72</td><td align="right">7.44</td><td align="right">0</td><td align="right">6</td><td align="right">0</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">0.01</td><td align="right">0</td><td align="right">0</td><td align="right">27.19</td></tr></tbody></table><p>:::info
Let&#x27;s ignore the <code>Tax</code> from the plot and table.
:::</p><h3>Detailed cost: Services, API Operations and Usages Type</h3><p>Let me write down the services used:</p><ul><li>AWS Config:<ul><li>API Operation: <code>None</code> </li><li>Usage Type: <code>EU-ConfigurationItemRecorded</code></li></ul></li><li>VPC: <ul><li>API Operation: <code>VpcEndpoint</code> </li><li>Usage Type: <code>EU-VpcEndpoint-Hours</code></li></ul></li><li>EC2-Other:<ul><li>API Operations: <code>NatGateway</code>, <code>AssociateAddressVPC</code>, here are the costs:</li><li>Usage Type: <code>EU-NatGateway-Hours</code>,<code>EU-ElasticIP:IdleAddress</code>, <code>EU-NatGateway-Bytes</code></li></ul></li></ul><table><thead><tr><th>API Operation</th><th align="right">NatGateway($)</th><th align="right">AssociateAddressVPC($)</th><th align="right">Total</th></tr></thead><tbody><tr><td>January</td><td align="right">7.28</td><td align="right">1.13</td><td align="right">8.41</td></tr><tr><td>February</td><td align="right">7.02</td><td align="right">2.02</td><td align="right">9.04</td></tr><tr><td>March</td><td align="right">0</td><td align="right">7.44</td><td align="right">7.44</td></tr></tbody></table><table><thead><tr><th>Usage Type</th><th align="right">EU-NatGateway-Hours($)</th><th align="right">EU-ElasticIP:IdleAddress($)</th><th align="right">EU-NatGateway-Bytes($)</th></tr></thead><tbody><tr><td>January</td><td align="right">7.2</td><td align="right">1.123</td><td align="right">0.08</td></tr><tr><td>February</td><td align="right">6.24</td><td align="right">2.019</td><td align="right">0.78</td></tr><tr><td>March</td><td align="right"></td><td align="right">7.435</td><td align="right"></td></tr></tbody></table><ul><li>CodeBuild: <ul><li>API Operation: <code>Build</code></li><li>No cost on March because no account was created neither enrolled</li></ul></li><li>Key Management Service:<ul><li>API Operation: <code>Unknown</code></li><li>Usage Type: <code>eu-west-1-KMS-Keys</code>,<code>eu-west-2-KMS-Keys</code></li></ul></li></ul><table><thead><tr><th>Usage Type</th><th align="right">eu-west-1-KMS-Keys($)</th><th align="right">eu-west-2-KMS-Keys($)</th><th align="right">Total</th></tr></thead><tbody><tr><td>January</td><td align="right">1.06</td><td align="right">0.5</td><td align="right">1.56</td></tr><tr><td>February</td><td align="right">1.24</td><td align="right">0.63</td><td align="right">1.87</td></tr><tr><td>March</td><td align="right">4</td><td align="right">2</td><td align="right">6</td></tr></tbody></table><ul><li>Lambda:<ul><li>API Operation: <code>Invoke</code></li><li>Usage Type: <code>EU-Lambda-GB-Second</code></li></ul></li></ul><h3>Analysis</h3><ul><li>The only services that cost independently of usage are:<ul><li>AWS Config</li><li>EC2-Other</li><li>KMS</li></ul></li><li>AWS Config is the highest cost. I will talk about this in the next section: <a href="#what-aws-config-does-can-i-reduce-it-cost">aws config section</a></li><li>Using the improvement to disable the VPC endpoints and NAT explained in my <a href="./1-delete-vpc-endpoints-and-nat.mdx">previous post</a>, in March the cost is 0 for the following operations:<ul><li><code>EU-VpcEndpoint-Hours</code> - service <code>VPC</code></li><li><code>EU-NatGateway-Hours</code> and <code>EU-NatGateway-Bytes</code> - service <code>EC2-Other</code></li></ul></li><li>However, <strong>there is still a cost in the <code>EC2-Other</code></strong> service, it is for the API Operation <code>AssociateAddressVPC</code> , usage type: <code>EU-ElasticIP:IdleAddress</code>. </li><li>The <strong>KMS cost has increase in March</strong>. I didn&#x27;t expect this one because I didn&#x27;t use AFT during that month.</li><li>Other services ( <code>S3</code> ,<code>DynamoDB</code> ,<code>Backup</code> ,<code>EC2-Instances</code> ,<code>CloudWatch</code> ) have no cost or less than 0.10.</li></ul><h3>Questions</h3><ul><li>What AWS Config does ? Can I reduce it cost ? </li><li>What does the operation <code>EU-ElasticIP:IdleAddress</code> do? How can I decrease this cost? </li><li>Why KMS cost increase in March if I didn&#x27;t use AFT? How can I decrease it?</li></ul><h2>What AWS Config does? Can I reduce it cost?</h2><p>AWS Config is a AWS service that allow us to record and evaluate resources configurations. You can check the full description <a href="https://aws.amazon.com/config/?nc1=h_ls">here</a>.
This service is been used by the AWS Control Tower as described next:</p><p>AWS Control Tower has a feature named <a href="https://docs.aws.amazon.com/controltower/latest/userguide/guardrails.html">Guardrails</a>, those are rules validated against resources created in enrolled accounts. This provides governance to AWS environments.
Those Guardrails can be preventive (ensuring your account maintain compliance) or Detective (detect noncompliance resources) based on the behavior.
The detective guardrails are implemented using AWS Config rules.
This means Control Tower call AWS Config to validate the configuration of the resources when a detective guardrails is active.</p><p>okey, too much theory, the most important, next are the two detective guardrails activated by default in a landing zone:</p><p><img src="resources/2/guardrails-default-detectives.png" alt="Guardrails detectives"/></p><p>:::danger
The next approach works for me because I&#x27;m using AFT sporadically and for personal projects. I don&#x27;t recommend it for companies because resource history might be required for compliance.
:::</p><p>Action done: </p><ol><li>Go to AWS Organizations. Create a OU, I name it <code>outside-act</code>.</li><li>Move the AFT account to the new OU.</li><li>Check it is not enrolled.</li></ol><p><img src="resources/2/aws-ct-account-outside-ou.png" alt="aws-ct-account-outside-ou"/></p><ol start="4"><li>Open the AWS Console, login using the AFT Account, go to AWS Config, open Settings, click on <code>Edit</code>. and select stop recording, save it.</li></ol><p><img src="resources/2/aws-config-settings.png" alt="aws-config-settings"/>
<img src="resources/2/aws-config-settings-edit.png" alt="aws-config-settings-edit"/>
<img src="resources/2/aws-config-setting-recorder-off.png" alt="aws-config-setting-recorder-off"/></p><p><img src="resources/2/costs-after-disable-aws-config-recorder.png" alt="costs-after-disable-aws-config-recorder"/></p><p>After disabling Recorder on April 19 the cost was reduced from <code>0.30 $</code> per day to <code>0.03 $</code></p><table><thead><tr><th>Service</th><th>2022-04-16</th><th>2022-04-17</th><th>2022-04-18</th><th>2022-04-19</th><th>2022-04-20</th><th>2022-04-21</th><th>2022-04-22</th></tr></thead><tbody><tr><td>Config($)</td><td>0.296</td><td><strong>0.296</strong></td><td><strong>0.236</strong></td><td><strong>0.008</strong></td><td>0.008</td><td>0.008</td><td>0.008</td></tr></tbody></table><h2>What does the operation <code>EU-ElasticIP:IdleAddress</code> do? How can I decrease this cost?</h2><p>I discovered there were two Elastic IP addresses not linked to any EC2 instances, this is why it is been charged in Idle state. I release them manually, through the AWS Console, so no more cost is generated. More details about why it was been charge <a href="https://aws.amazon.com/premiumsupport/knowledge-center/elastic-ip-charges/">here</a>.</p><p>As we want to avoid manual intervention, I made the elastic IP creation depend on the <code>aft_vpc_nat_gateway</code> parameter I introduce for reducing NAT costs in my <a href="./1-delete-vpc-endpoints-and-nat.mdx">previous post.</a></p><p><img src="resources/2/elastic-ip-modification-in-tf.png" alt="elastic-ip-modification"/></p><p><a href="https://github.com/cangulo-aws-aft/terraform-aws-control_tower_account_factory/commit/e11466b8e6beaf4364f0343b5d44f0939050dbf3">Commit</a></p><h2>KMS Costs</h2><p>:::info
I will answer this one in my next post. Too much for this one.
:::</p><h2>Side Notes:</h2><h3>Wait Carlos, were you using the Free Tier?</h3><p>Yes, I was, and that might reduce the final costs I had, but I don&#x27;t expect them to be significantly different nor to change any conclusion of this article. </p><p>Next is my remaining Free Tier quota on April 18, as you see some services already exceeded the free layer though I haven&#x27;t used the AFT resources since later February. </p><p><img src="resources/2/free-tier-stats.png" alt="free tier stats"/></p><h3>Audit and Log AWS Accounts costs</h3><p>For using AWS Control Tower there are 3 accounts required:</p><ul><li>Audit Account.</li><li>Log Archive Account.</li><li>AFT Account where all the resources to process account creation request are.</li></ul><p>Next are the costs per account</p><table><thead><tr><th>Linked Account Name</th><th>cangulo_aft ($)</th><th>Log Archive ($)</th><th>Audit ($)</th></tr></thead><tbody><tr><td>January</td><td>61.2</td><td>1.8</td><td>0.2</td></tr><tr><td>February</td><td>63.3</td><td>1.5</td><td>0.02</td></tr><tr><td>March</td><td>27.2</td><td>2.8</td><td>0.01</td></tr></tbody></table><p>:::info</p><p>In this post I&#x27;m only referring to the AFT account costs. </p><p>:::</p><h2>References:</h2><ul><li><a href="https://docs.aws.amazon.com/controltower/latest/userguide/getting-started-with-control-tower.html">Starting with Control Tower</a></li><li><a href="https://docs.aws.amazon.com/controltower/latest/userguide/guardrails.html">control tower user guide</a></li></ul><h3>Git Repositories</h3><p><a href="https://github.com/hashicorp/learn-terraform-aft-account-provisioning-customizations">learn-terraform-aft-account-provisioning-customizations</a><br/>
<a href="https://github.com/hashicorp/learn-terraform-aft-account-customizations">learn-terraform-aft-account-customizations</a><br/>
<a href="https://github.com/hashicorp/learn-terraform-aft-global-customizations">learn-terraform-aft-global-customizations</a><br/>
<a href="https://github.com/hashicorp/learn-terraform-aft-account-request">learn-terraform-aft-account-request</a></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Control Tower - Reducing Cost 1]]></title>
            <link>https://cangulo.github.io/blog/aws/control-tower/1-delete-vpc-endpoints-and-nat</link>
            <guid>/aws/control-tower/1-delete-vpc-endpoints-and-nat</guid>
            <pubDate>Sat, 22 Jan 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[This post explains some customizations I did to save AWS Control Tower costs. I followed the next article to set it up: Manage AWS Accounts Using Control Tower Account Factory for Terraform. I recommend you read it before continuing. Basic knowledge about AWS and Terraform is required.]]></description>
            <content:encoded><![CDATA[<p>:::info
This post explains some customizations I did to save AWS Control Tower costs. I followed the next article to set it up: <a href="https://learn.hashicorp.com/tutorials/terraform/aws-control-tower-aft#create-aws-aft-organizational-unit-and-account">Manage AWS Accounts Using Control Tower Account Factory for Terraform</a>. I recommend you read it before continuing. Basic knowledge about AWS and Terraform is required.
:::</p><h2>Context</h2><p>Whenever I want to start a new project, I create an AWS account for each environment, I do it to separate domains and costs. So far, I have been doing this manually, but then I discover the Account Factory for Terraform (AFT) as part of the AWS Control Tower services. </p><p>AFT defines a GitOps process to automate the account creation and update. It is based on two main elements: </p><ol><li>Git repositories where the account creation request and customizations are defined.</li><li>AWS resources used in the account creation/update process. All of them are based on the repository code. Some of them are CodePipeline, Dynamo tables, Lambdas, and Step Functions.</li></ol><p>I don&#x27;t want to go into details, but I think it is worth mentioning that this automatization simplifies the whole process, not only because we avoid manual operations (that is always nice, right?), but because it allows us to align different AWS accounts.</p><p>A customization example could be to define a Budget after creating the account. We can add a notification when we are close to a maximum amount (in fact, this was my main goal at first, to avoid any unexpected cost 😁). Next are other examples:</p><ul><li>Create default resources like S3 buckets</li><li>Add SSM parameters to describe the account</li><li>Add custom policies</li></ul><p>:::info
I&#x27;m not going to go into the customization details in this article. I just want to point out a few examples. I will explain it in a separate post in the future.
:::</p><h2>Problem: Costs</h2><p>AFT does not have a cost itself, the cost depends <a href="https://docs.aws.amazon.com/controltower/latest/userguide/aft-pricing.html">on the resources deployed and used</a>. Next are the main costs per resource after a few days of using it:</p><ol><li>VPC Endpoints: <a href="https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints.html">billed hourly</a>.</li><li>NatGateway.</li></ol><p>I found it in the Cost Explorer of my root account, grouping by API Operation:</p><p><img src="./resources/1/costs-using-aws-ct-aft.png" alt="costs"/></p><h2>Solution</h2><h3>Delete the VPC Endpoints when not used</h3><p>The AFT repository (<a href="https://github.com/aws-ia/terraform-aws-control_tower_account_factory">terraform-aws-control_tower_account_factory</a>) offers  the flag <code>aft_vpc_endpoints</code> to enable/disable the VPC Endpoints. As those are billed hourly, it doesn&#x27;t make sense to have them on if you are not using them. So, to save costs, only turn them on before requesting a new account, and once it is finished, turn them off. The idea is simple, let&#x27;s see that in practice:</p><p>The basic TF code that creates the AFT infrastructure is:</p><pre><code class="language-terraform">module &quot;aft&quot; {
  source                      = &quot;github.com/aws-ia/terraform-aws-control_tower_account_factory&quot;

  ct_management_account_id    = var.ct_management_account_id
  log_archive_account_id      = var.log_archive_account_id
  audit_account_id            = var.audit_account_id
  aft_management_account_id   = var.aft_management_account_id
  ct_home_region              = var.ct_home_region
  tf_backend_secondary_region = &quot;us-west-2&quot;

  vcs_provider                                  = &quot;github&quot;
  account_request_repo_name                     = &quot;${var.github_username}/learn-terraform-aft-account-request&quot;
  global_customizations_repo_name               = &quot;${var.github_username}/learn-terraform-aft-global-customizations&quot;
  account_customizations_repo_name              = &quot;${var.github_username}/learn-terraform-aft-account-customizations&quot;
  account_provisioning_customizations_repo_name = &quot;${var.github_username}/learn-terraform-aft-account-provisioning-customizations&quot;
}
</code></pre><p>Once we have created the infrastructure by executing a <code>terraform apply</code>, the VPC endpoints are enabled by default, we process to send the account creation request (explained in the <a href="https://learn.hashicorp.com/tutorials/terraform/aws-control-tower-aft#create-aws-aft-organizational-unit-and-account">tutorial</a>). Once it is finished, we set the <code>aft_vpc_endpoints</code> flag to false:</p><pre><code class="language-terraform" metastring="{5}">module &quot;aft&quot; {
  source                      = &quot;github.com/aws-ia/terraform-aws-control_tower_account_factory&quot;

  ...

  aft_vpc_endpoints                             = false
}
</code></pre><p>We reexecute <code>terraform apply</code> and done! VPC endpoints deleted and costs reduced!</p><h3>Delete the NAT related resources when not used</h3><p>Maybe, the first approach we think is to manually delete the NAT resources. Then, before queuing any account creation request, we use Terraform to recreate them. That might work, but it involves manual intervention on in the AWS Console for every request, we don&#x27;t want that. </p><p>So, taking into account that the AFT code is in a GitHub repository, I thought it was better to fork it and add a new flag to conditionally create the NAT resources. So, I did the next steps:</p><ol><li>I forked the AWS GH repo <a href="https://github.com/aws-ia/terraform-aws-control_tower_account_factory">aws-ia/terraform-aws-control_tower_account_factory</a> in <a href="https://github.com/cangulo-aws-aft/terraform-aws-control_tower_account_factory">cangulo-aws-aft/terraform-aws-control_tower_account_factory</a>.</li><li>I created a new flag called <code>aft_vpc_nat_gateway</code> following the <code>aft_vpc_endpoints</code> model.</li><li>I modify the NAT resources to depend on the new flag. </li></ol><p>Everything is done in <a href="https://github.com/cangulo-aws-aft/terraform-aws-control_tower_account_factory/commit/d8cfd2584f4cec37e1a91d213f823191cec201d3">this commit</a>.</p><p>Then, I simply update the &quot;aft&quot; module source to my fork and provide the new flag. Next is the result:</p><pre><code class="language-terraform" metastring="{22}">module &quot;aft&quot; {

  # source = &quot;github.com/cangulo-aws-aft/terraform-aws-control_tower_account_factory&quot; # repo in the cloud

  # source                      = &quot;github.com/cangulo-aws-aft/terraform-aws-control_tower_account_factory&quot;
  source = &quot;../terraform-aws-control_tower_account_factory&quot; # repo in the same local path

  ct_management_account_id    = var.ct_management_account_id
  log_archive_account_id      = var.log_archive_account_id
  audit_account_id            = var.audit_account_id
  aft_management_account_id   = var.aft_management_account_id
  ct_home_region              = var.ct_home_region
  tf_backend_secondary_region = var.tf_backend_secondary_region

  vcs_provider                                  = &quot;github&quot;
  account_request_repo_name                     = &quot;${var.github_username}/account-request&quot;
  account_provisioning_customizations_repo_name = &quot;${var.github_username}/account-provisioning-customizations&quot;
  global_customizations_repo_name               = &quot;${var.github_username}/global-customizations&quot;
  account_customizations_repo_name              = &quot;${var.github_username}/account-customizations&quot;

  aft_feature_delete_default_vpcs_enabled = false
  aft_vpc_aws_nat_gateway                 = false
  aft_vpc_endpoints                       = false
}
</code></pre><h3>Reduced Costs</h3><p><img src="./resources/1/reduced-costs.jpg" alt="reduced-costs"/></p><p>I deactivated the VPC Endpoints since the day 11, NAT costs disappeared next days. </p><h2>References:</h2><ul><li>Youtube Tutorial for setting up AWS Control Tower: <a href="https://www.youtube.com/watch?v=CwRy0t8nfgM">Enable AWS Control Tower for Existing Organizations</a>  </li><li><a href="https://learn.hashicorp.com/tutorials/terraform/aws-control-tower-aft#create-aws-aft-organizational-unit-and-account">Manage AWS Accounts Using Control Tower Account Factory for Terraform</a>  </li><li><a href="https://aws.amazon.com/blogs/aws/new-aws-control-tower-account-factory-for-terraform/">Account Factory for Terraform</a></li></ul><h3>Git Repositories</h3><p><a href="https://github.com/hashicorp/learn-terraform-aft-account-provisioning-customizations">learn-terraform-aft-account-provisioning-customizations</a><br/>
<a href="https://github.com/hashicorp/learn-terraform-aft-account-customizations">learn-terraform-aft-account-customizations</a><br/>
<a href="https://github.com/hashicorp/learn-terraform-aft-global-customizations">learn-terraform-aft-global-customizations</a><br/>
<a href="https://github.com/hashicorp/learn-terraform-aft-account-request">learn-terraform-aft-account-request</a></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Interactive bookmarks menu v2]]></title>
            <link>https://cangulo.github.io/blog/bash/5-interactive-bookmarks-v2</link>
            <guid>bash/5-interactive-bookmarks-v2</guid>
            <pubDate>Mon, 21 Dec 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post, I am going to improve the interactive bookmark I created in a previous post.]]></description>
            <content:encoded><![CDATA[<p>In this post, I am going to improve the interactive bookmark I created in a <a href="../1-interactive-bookmarks/1-interactive-bookmarks.mdx">previous post</a>.</p><h2>Requirements</h2><ul><li>Linux (I&#x27;m using <a href="https://elementary.io">Elementary OS</a>, a Ubuntu-based distro, try it!)</li><li><a href="https://github.com/junegunn/fzf">fzf</a> command-line fuzzy finder</li><li>Remember to add execution permissions to the scripts through <code>chmod +x</code></li><li>This article improves the interactive bookmark menu implemented in the previous post: <a href="../1-interactive-bookmarks/1-interactive-bookmarks.mdx"><em>Create an interactive bookmarks menu in your terminal</em></a></li></ul><h2>Improvements introduced</h2><ol><li>Add one directory layer</li><li>Open VS Code in the repository</li></ol><h3>Add one directory layer</h3><p>I have a global path for all the repositories I clone locally, it is <code>/home/cangulo/repos</code>. As I have a lot, I grouped them into folders per organization or custom name.</p><table><thead><tr><th>Organization/ custom name</th><th>Repository</th></tr></thead><tbody><tr><td>cangulo-actions</td><td>cangulo.nuke.prcommitsvalidations</td></tr><tr><td>cangulo-actions</td><td>cangulo.nuke.releasecreator</td></tr><tr><td>cangulo-actions</td><td>workflows</td></tr><tr><td>cangulo-nugets</td><td>cangulo.changelog</td></tr><tr><td>cangulo-nugets</td><td>cangulo.changelog.github.io</td></tr><tr><td>cangulo-nugets</td><td>cangulo.common.testing</td></tr><tr><td>old-projects</td><td>cangulo.build</td></tr><tr><td>old-projects</td><td>cangulo.cicd</td></tr><tr><td>old-projects</td><td>cangulo.cicd-gh-action</td></tr><tr><td>temps</td><td><em>any temporary repository</em></td></tr></tbody></table><p>The <em>organization / custom name</em> will be the first layer, while the repositories are the second one. Next is the folder structure:</p><pre><code class="language-bash">├── cangulo-actions
│   ├── cangulo.nuke.prcommitsvalidations
│   ├── cangulo.nuke.releasecreator
│   └── workflows
├── cangulo-nugets
│   ├── cangulo.changelog
│   ├── cangulo.changelog.github.io
│   └── cangulo.common.testing
├── old-projects
│   ├── cangulo.build
│   ├── cangulo.cicd
│   └── cangulo.cicd-gh-action
└── temp
    ├── dotnet-docker
    └── gsd
</code></pre><h3>Open VS Code in the repository</h3><p>Once I choose a repository, I would like to open it using VS Code. </p><h3>Demo</h3><p><img src="goal.gif" alt="goal"/></p><h2>Implementation</h2><pre><code class="language-bash" metastring="file=./code/listbookmarks.sh#L3- {4-7,12-17}" file="./code/listbookmarks.sh#L3-"></code></pre><div label="listBookmarks function" link="posts/bash/5-interactive-bookmarks-v2/code/listbookmarks.sh"></div><p>Let me write down the changes introduced:</p><ol><li>Bookmarks now have two properties: <em>name</em> and <em>path</em>. </li></ol><pre><code class="language-json" metastring="file=code/bookmarks.json#L3-L6" file="code/bookmarks.json#L3-L6"></code></pre><ul><li>name: string to identify the organization / custom name folder. Without spaces. e.g. for cangulo-actions -&gt; Actions</li><li>path: full path to first layer directories mentioned before.</li></ul><details><summary>Full Bookmark file</summary><pre><code class="language-json" metastring="file=code/bookmarks.json" file="code/bookmarks.json"></code></pre><div label="bookmarks" link="posts/bash/5-interactive-bookmarks-v2/code/bookmarks.json"></div></details><ol start="2"><li>The path to the bookmarks file is set in the environment variable <code>$BOOKMARKS_FILE</code>. We don&#x27;t have it hardcoded in the function.</li></ol><pre><code class="language-bash" metastring="file=./code/listbookmarks.sh#L5 {1}" file="./code/listbookmarks.sh#L5"></code></pre><ol start="3"><li>I now use <code>jq</code> to query both attributes <code>(.[] | [.name,.path])</code> and output them in the columns <code>[&quot;NAME&quot;, &quot;PATH&quot;]</code>  as a tab-separated-value <code>@tsv</code>:</li></ol><pre><code class="language-bash" metastring="file=./code/listbookmarks.sh#L5-L8" file="./code/listbookmarks.sh#L5-L8"></code></pre><p><img src="jq-updated.png" alt="jq-updated"/></p><p>Problem: columns are not aligned (see <em>oldprojects</em> row)</p><ol start="4"><li>In order to align the <code>jq</code> output before piping it to <code>fzf</code>, I use the <code>column -t</code> command. <a href="https://linux.die.net/man/1/column">Reference</a></li></ol><pre><code class="language-bash" metastring="file=./code/listbookmarks.sh#L5-L10 {5}" file="./code/listbookmarks.sh#L5-L10"></code></pre><p><img src="column.png" alt="column"/></p><ol start="5"><li>Once a bookmark is selected, the full row is returned. I</li></ol><p><img src="fzf_return_full_row.gif" alt="fzf_return_full_row"/></p><p>Then, I have to extract the path. First, I delete the repeated spaces (<code>tr -s &#x27; &#x27;</code>). Secondly, I choose the second column(<code>cut -f2 -d &#x27; &#x27;</code>). The <code>-d &#x27; &#x27;</code> parameter is to set columns delimiter to a whitespace.</p><p><img src="trim-selection.png" alt="trim-selection"/></p><ol start="5"><li>I have created the function <code>lsf</code> to list the current directories using <code>fzf</code>, navigate to the one selected and execute a command provided as first parameter <code>$1</code>. In our case <code>code</code>. </li></ol><pre><code class="language-bash" metastring="file=./code/listbookmarks.sh#L27-L37 {8}" file="./code/listbookmarks.sh#L27-L37"></code></pre><p>Please note the <code> eval &quot;\$command .&quot;</code> statement for executing the command provided.</p><h2>Adding this to your Terminal Profile</h2><p>You can add this into your Bash / Zsh profile. You can follow the next steps:</p><ol><li>Define your bookmarks in a json file following the <em>name,path</em> model</li><li>In your profile, append its path in the <code>$BOOKMARKS_FILE</code> variable</li><li>Append the functions <code>listBookmarks</code> and <code>lsf</code>.</li><li>Append a call to the <code>listBookmarks</code> function at the end of the profile, so every time you open a terminal it execute it. </li></ol><h2>lsf function</h2><p>I just want to mention you can use the  <code>lsf</code> function separately to make navigation through directories faster. Also, remember it accepts as a parameter a command to execute in the directory selected. Give it a try and add import it in your profile.</p><p><img src="lsf_faster_navigation.gif" alt="lsf_faster_navigation"/></p><h2>Final Notes</h2><p>Do you see any other improvement to include? What commands would you provide when using <code>lsf</code> ? Share them in the comments below.</p><div id="UtEUhkfriklonVdweC"></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How to use a repository for importing your bash scripts and shortcuts]]></title>
            <link>https://cangulo.github.io/blog/bash/4-create-config-repo</link>
            <guid>bash/4-create-config-repo</guid>
            <pubDate>Thu, 17 Dec 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post, I will explain how to load custom variables by reading a JSON file, this will be done every time we open a Terminal. I will also improve the shortcuts we create in the previous posts.]]></description>
            <content:encoded><![CDATA[<p>In this post, I will explain how to load custom variables by reading a JSON file, this will be done every time we open a Terminal. I will also improve the shortcuts we create in the previous posts.</p><p>:::info Template ready to use!
The <a href="https://github.com/cangulo-templates/linux-terminal-profile">cangulo-templates/linux-terminal-profile</a> repository contains a ready-to-use template based on this article.
:::</p><h2>Requirements</h2><ul><li>Linux (I&#x27;m using <a href="https://elementary.io">Elementary OS</a>, a Ubuntu-based distro, try it!)</li><li><a href="https://code.visualstudio.com">VS Code</a>. If you don&#x27;t want to use it, change all the <code>code</code> commands in the bash code for your text editor. Alternatives: <em>gedit</em> or <a href="https://gitlab.gnome.org/GNOME/gnome-text-editor">gnome-text-editor</a>.</li><li><a href="https://github.com/junegunn/fzf">fzf</a> command-line fuzzy finder</li></ul><h2>Notes</h2><ul><li>Remember to add execution permissions to the scripts through <code>chmod +x</code></li><li>Profile script: <code>$HOME/.bashrc</code> for bash terminal and <code>$HOME/.zshrc</code> for zsh </li></ul><h2>Problem</h2><p>Simplify, as much as possible, the process to set up my shortcuts every time I migrate to a new computer, personal or work. This process is: download and setups all my scripts in the Bash profile.</p><h2>Idea</h2><p>Remember the concept <em>Behavior vs Configuration</em> I explained in my <a href="../3-load-vars/3-load-vars.mdx#behavior-vs-configuration">previous post</a>? We are going to continue using it 😁. Let me list down the main points:</p><ul><li>Variables are stored in a JSON file. We want those variables to be available during all the terminal sessions.</li><li>Functions depend on those variables, values that could change depending on the PC your use, for example paths, shouldn&#x27;t be hard-coded.</li><li>Both, variables and functions are added in the Bash Profile.</li></ul><p>Nice, now that we have the main points, let me show the implementation.</p><h2>Implementation</h2><p>First, we have the JSON file containing the variables:</p><pre><code class="language-json" metastring="file=./code/1-profile-settings.json" file="./code/1-profile-settings.json"></code></pre><p>Each JSON key will be an environment variable, I prefer to define them in upper case to differentiate them from other variables we define during the terminal session.</p><p>Then, in the bash profile we only have to do the next actions:</p><ol><li>Export the path to the JSON settings. My convention is to call this variable as <code>SETTINGS_FILE</code>.</li><li>Call a script to load all the variables and functions using the previous settings. Let&#x27;s call this script <code>load-custom-profile.sh</code>.</li></ol><p>Next is the code for that. Please append it in your profile.</p><pre><code class="language-bash"># Update FULL_PATH_TO_JSON_SETTINGS with yours
export SETTINGS_FILE=&quot;FULL_PATH_TO_JSON_SETTINGS&quot;
source FULL_PATH/load-custom-profile.sh
</code></pre><p>Please note we use the <code>export</code> keyword, which sets <code>SETTINGS_FILE</code> as an environment variable. In that way, it will be available for other scripts. Please check this <a href="https://www.baeldung.com/linux/bash-variables-export">link</a> for more details.</p><h3>load-custom-profile.sh</h3><p>This script should perform the next actions:</p><ul><li>Verify <code>$SETTINGS_FILE</code> is defined and valid:<ul><li>String is not empty</li><li>Path provided exists</li></ul></li><li>Read the JSON file and export the variables. The command is based on <code>jq</code> and <code>eval</code> as explained in my <a href="../3-load-vars/3-load-vars.mdx">previous post</a> for more details. The main difference now is the use of the <code>export</code> command, following the pattern: <code>export KEY=&#x27;VALUE&#x27;</code></li></ul><pre><code class="language-bash" metastring="file=./code/load-custom-profile.sh" file="./code/load-custom-profile.sh"></code></pre><p>Next are the scripts stored in <code>$SCRIPTS_FOLDER</code>:</p><ul><li>aliases:</li></ul><div><div value="bash" label="bash" default=""><pre><code class="language-bash" metastring="file=./code/scripts/aliases-bash.sh" file="./code/scripts/aliases-bash.sh"></code></pre><div label="aliases-bash.sh" link="posts/bash/4-create-config-repo/code/scripts/aliases-bash.sh"></div></div><div value="zsh" label="zsh"><pre><code class="language-bash" metastring="file=./code/scripts/aliases-zsh.sh" file="./code/scripts/aliases-zsh.sh"></code></pre><div label="aliases-zsh.sh" link="posts/bash/4-create-config-repo/code/scripts/aliases-zsh.sh"></div></div></div><ul><li>functions:</li></ul><pre><code class="language-bash" metastring="file=./code/scripts/functions.sh" file="./code/scripts/functions.sh"></code></pre><ul><li>Bookmarks file referenced in the variable <code>BOOKMARKS_FILE</code> , and used in the <code>listBookmarks</code>  function:</li></ul><pre><code class="language-json" metastring="file=./code/2-bookmarks.json" file="./code/2-bookmarks.json"></code></pre><h2>Demo</h2><p><img src="demo.gif" alt="demo"/></p><h2>Repository</h2><p>If we store the settings and the implementations in a repository (e.g. GitHub) , we just need to reference them in the profile script the same way we have done so far:</p><pre><code class="language-bash"># Update LOCAL_REPO_FULL_PATH with yours
export SETTINGS_FILE=&quot;LOCAL_REPO_FULL_PATH/settings.local.json&quot;
source LOCAL_REPO_FULL_PATH/load-custom-profile.sh
</code></pre><p>I recommend you to have a <code>settings.template.json</code> with the empty variables as next:</p><pre><code class="language-json" metastring="file=./code/3-profile-settings.template.json" file="./code/3-profile-settings.template.json"></code></pre><p>In that way, when you clone the repo locally, you duplicate it, rename copy to <code>settings.local.json</code>, and fill the values. Add it to your <code>gitignore</code> to avoid pushing it.</p><h2>Final Notes</h2><p>wow, this post is the longest one I have done so far! Do you have another approach for importing scripts or settings? How would you do it? Let me know in the comments below.</p><div id="d3mlE7uhX8KFgEmY"></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Load custom variables at Terminal startup]]></title>
            <link>https://cangulo.github.io/blog/bash/3-load-vars</link>
            <guid>bash/3-load-vars</guid>
            <pubDate>Tue, 15 Dec 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post, I will explain how to import custom environment variables from a JSON file.]]></description>
            <content:encoded><![CDATA[<p>In this post, I will explain how to import custom environment variables from a JSON file.
I will also improve the shortcuts we create in the previous posts.</p><h2>Requirements</h2><ul><li>Linux (I&#x27;m using <a href="https://elementary.io">Elementary OS</a>, a Ubuntu-based distro, try it!)</li><li><a href="https://code.visualstudio.com">VS Code</a>. If you don&#x27;t want to use it, change all the <code>code</code> commands in the bash code for your text editor. Alternatives: <em>gedit</em> or <a href="https://gitlab.gnome.org/GNOME/gnome-text-editor">gnome-text-editor</a>.</li><li><a href="https://github.com/junegunn/fzf">fzf</a> command-line fuzzy finder</li></ul><h2>Notes</h2><ul><li>Remember to add execution permissions to the scripts through <code>chmod +x</code></li><li>Profile script: <code>$HOME/.bashrc</code> for bash terminal and <code>$HOME/.zshrc</code> for zsh </li></ul><h2>Variables</h2><p>Let&#x27;s say I want to define some variables as:</p><ul><li>my local github repositories path</li><li>my documents path</li><li>path to a specific file, in this case, the path to a JSON file containing some bookmarks I have, check my <a href="../1-interactive-bookmarks/1-interactive-bookmarks.mdx">previous post</a></li></ul><p>By defining them in the profile script as:</p><pre><code class="language-bash" metastring="file=./code/1-declare-vars.sh#L3-" file="./code/1-declare-vars.sh#L3-"></code></pre><p>We can use them during the terminal session.</p><p><img src="use-localrepo-variable.gif" alt="using the variables after loading the terminal"/></p><p>Let&#x27;s append the next function and aliases at the bash profile. Please note those are using the variables defined before.</p><pre><code class="language-bash" metastring="file=./code/2-add-functions.sh#L3-" file="./code/2-add-functions.sh#L3-"></code></pre><p>Now, we can use them after opening the Terminal.</p><p><img src="use-gotoRepos-function.gif" alt="using the variables after loading the terminal"/></p><h2>Behavior vs Configuration</h2><p>In <a href="../1-interactive-bookmarks/1-interactive-bookmarks.mdx">a previous post</a>, the <code>listBookmarks</code> function has the <code>bookmarksFile</code> hardcoded. </p><pre><code class="language-bash" metastring="file=../1-interactive-bookmarks/code/listbookmarks.sh#L3-L4" file="../1-interactive-bookmarks/code/listbookmarks.sh#L3-L4"></code></pre><p>As you see, its value refers to the <code>bookmarks.json</code> location. What happens if we move that file to another folder? We would have to update the function. For one variable this doesn&#x27;t seem to be a problem, right? But what if it is hardcoded in more functions? we would have to update them all, that is not extensible!</p><p>Let&#x27;s define two terms here:</p><ul><li>Behavior: Functions implementation.</li><li>Configuration: Input parameters that the function relies on. In this case, <code>bookmarksFile</code>. </li></ul><p>By setting all the parameters outside the functions, we are creating a central place for the configuration.</p><pre><code class="language-bash" metastring="file=./code/1-declare-vars.sh#L4-" file="./code/1-declare-vars.sh#L4-"></code></pre><p>And by calling those from the functions:</p><pre><code class="language-bash" metastring="file=./code/2-add-functions.sh#L8-L9" file="./code/2-add-functions.sh#L8-L9"></code></pre><p>We are <strong>decoupling</strong> configuration from behavior.  If we want to migrate or share this setup, we won&#x27;t need to look at the function implementations, we would only need to update the parameters.</p><div id="d3mlE7uhX8KFgEmY"></div><h2>One extra mile: Define the parameters as JSON</h2><p>Let&#x27;s migrate the variables to a JSON file as follows. Please note all the paths are now absolute.</p><pre><code class="language-json" metastring="file=./code/3-vars.json" file="./code/3-vars.json"></code></pre><p>To set the JSON keys as the parameters name we have to:</p><ol><li>Define the json file path. We will consider those as the main settings.</li><li>Use the <code>jq</code> command to retrieve the keys and values.</li><li>Use the <code>eval</code> command to execute the <code>key=value</code>  for each one.</li></ol><p>Next is the solution, replace the variables declaration in your profile for this.</p><pre><code class="language-bash">settingsFile=&quot;/home/cangulo/repos/cangulo-blog/cangulo.github.io/blog/posts/bash/3-setup-custom-env-variables/code/3-vars.json&quot;
eval &quot;$(jq -r &#x27;to_entries | .[] | .key + &quot;=&quot; + (.value | @sh)&#x27; &lt;$settingsFile)&quot;
</code></pre><details><summary>In case you want to go into the solution details. Click here.</summary><p>References:</p><ul><li>Settings json keys as variables<code>jq</code>. <a href="https://unix.stackexchange.com/a/413886">Link</a></li><li>What <code>@sh</code> means in <code>jq</code>. Quote string for bash. <a href="https://stedolan.github.io/jq/manual/">Link</a></li></ul><p><code>jq -r &#x27;to_entries&#x27;</code>  structures the json as key/value pair array:</p><p><img src="./details/1-to_entries.png" alt="1-to_entries.png"/></p><p><code>jq -r &#x27;to_entries | .[]&#x27;</code>  prepare the array items for the iteration:</p><p><img src="./details/2-iterate-over-array-items.png" alt="2-iterate-over-array-items.png"/></p><p><code>jq -r &#x27;to_entries | .[] | .key + &quot;=&quot; + .value&#x27;</code> build the <code>key=value</code> expressions </p><p><img src="./details/3-build-variable-declaration-code.png" alt="3-build-variable-declaration-code.png"/></p><p><code>jq -r &#x27;to_entries | .[] | .key + &quot;=&quot; + (.value | @sh)&#x27;</code> format the expression
<img src="./details/4-format-declaration.png" alt="4-format-declaration.png"/></p></details><p>Nothing more for Today! Do you think this is a good approach? How would you do it? Let me know in the comments below.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Add shortcuts to your bash terminal]]></title>
            <link>https://cangulo.github.io/blog/bash/2-add-shortcuts</link>
            <guid>bash/2-add-shortcuts</guid>
            <pubDate>Mon, 14 Dec 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post, I will define shortcuts in my bash terminal. The implementation is based on using aliases and functions. Super simple!]]></description>
            <content:encoded><![CDATA[<p>In this post, I will define shortcuts in my bash terminal. The implementation is based on using aliases and functions. Super simple!</p><h2>Requirements</h2><ul><li>Linux (I&#x27;m using <a href="https://elementary.io">Elementary OS</a>, a Ubuntu-based distro, try it!)</li><li><a href="https://code.visualstudio.com">VS Code</a>. If you don&#x27;t want to use it, change all the <code>code</code> commands in the bash code for your text editor. Alternatives: <em>gedit</em> or <a href="https://gitlab.gnome.org/GNOME/gnome-text-editor">gnome-text-editor</a>.</li><li>Remember to add execution permissions to the scripts through <code>chmod +x</code></li></ul><h2>Aliases</h2><p>You can create <strong>aliases</strong> to avoid type long commands. Next are some examples:</p><div><div value="bash" label="bash" default=""><pre><code class="language-bash" metastring="file=./code/scripts/aliases-bash.sh#L3-" file="./code/scripts/aliases-bash.sh#L3-"></code></pre><div label="aliases-bash.sh" link="posts/bash/2-add-shortcuts/code/scripts/aliases-bash.sh"></div></div><div value="zsh" label="zsh"><pre><code class="language-bash" metastring="file=./code/scripts/aliases-zsh.sh#L3-" file="./code/scripts/aliases-zsh.sh#L3-"></code></pre><div label="aliases-zsh.sh" link="posts/bash/2-add-shortcuts/code/scripts/aliases-zsh.sh"></div></div></div><p><img src="goToReposExecution.gif" alt="goToReposExecution"/></p><p>Please note <code>$HOME</code> is an environment variable defined by the system, it refers to your home path, in my case <code>/home/carlos</code>.</p><h2>Functions</h2><p>You can also define functions as shortcuts for daily tasks. I have the next ones:</p><pre><code class="language-bash" metastring="file=./code/scripts/functions.sh" file="./code/scripts/functions.sh"></code></pre><p><em>No need to focus on the implementation, I just want to point out some examples.</em></p><p><img src="functionsExecution.gif" alt="functionsExecution"/></p><h2>How to integrate those shortcuts in the bash terminal?</h2><p>In order to load the shortcuts every time we open a terminal, we have to append them in the shell profile (<code>$HOME/.bashrc</code> for bash terminal, and <code>$HOME/.zshrc</code> for zsh). </p><p>However, the profile script will become bigger for every new shortcut we add, to make this extensible we will <em>source</em> (<a href="https://linuxize.com/post/bash-source-command/">load</a>) the shortcuts from separate scripts. Let me list them:</p><ol><li><code>alias-bash.sh.sh</code> /  <code>alias-zsh.sh</code></li><li><code>functions.sh</code></li></ol><p>Append the next code to your profile:</p><pre><code class="language-bash" metastring="file=./code/sourceScripts.sh" file="./code/sourceScripts.sh"></code></pre><details><summary>Some notes about loading the functions:</summary><p>if you want to use the functions in scripts that you call manually from the terminal, you have to <code>export</code> them as next:</p><div><div value="bash" label="bash" default=""><pre><code class="language-bash">funcName(){

}
export -f funcName
</code></pre></div><div value="zsh" label="zsh"><pre><code class="language-bash">funcName(){

}
export funcName
</code></pre></div></div><p><a href="https://www.baeldung.com/linux/bash-variables-export">reference</a></p></details><p>Nothing else! I hope this saves you some time using the terminal. Do you have similar shortcuts? Share them in the comments below.</p><div id="ZVik7pBtu9dNS"></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Create an interactive bookmarks menu in your terminal]]></title>
            <link>https://cangulo.github.io/blog/bash/1-interactive-bookmarks</link>
            <guid>bash/1-interactive-bookmarks</guid>
            <pubDate>Fri, 11 Dec 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post, I am going to implement an interactive bookmarks menu using fzf in bash Terminal.]]></description>
            <content:encoded><![CDATA[<p>In this post, I am going to implement an interactive bookmarks menu using fzf in bash Terminal.</p><h2>Requirements</h2><ul><li>Linux (I&#x27;m using <a href="https://elementary.io">Elementary OS</a>, a Ubuntu-based distro, try it!)</li><li><a href="https://github.com/junegunn/fzf">fzf</a> command-line fuzzy finder</li><li>Remember to add execution permissions to the scripts through <code>chmod +x</code></li></ul><h2>Demo</h2><p><img src="goal.gif" alt="goal"/></p><p>As you see, every time I call <code>listBookmarks</code> the following paths are listed interactively:</p><ul><li>/home/cangulo/repos/cangulo-tf</li><li>/home/cangulo/repos/cangulo-nuke</li></ul><p>I can move through them using the up/down keys, and navigate into by pressing Enter.</p><p>On the other hand, in case similar paths are listed, I can filter by typing keywords.</p><p><img src="demo_filter.gif" alt="goal"/></p><h2>Implementation</h2><pre><code class="language-bash" metastring="file=./code/listbookmarks.sh" file="./code/listbookmarks.sh"></code></pre><div label="listBookmarks function" link="posts/bash/1-interactive-bookmarks/code/listbookmarks.sh"></div><p>Let me define the basic structure:</p><ol><li>Read the paths (i.e. <em>bookmarks</em>)</li><li>List them in an interactive way</li><li>Once a bookmark is selected, navigate to it</li></ol><p>Now let&#x27;s dive into the details:</p><h3>1. Read the bookmarks</h3><p>First, in order to make this extensible, the paths are listed in a JSON file:</p><pre><code class="language-json" metastring="file=code/bookmarks.json" file="code/bookmarks.json"></code></pre><div label="bookmarks" link="posts/bash/1-interactive-bookmarks/code/bookmarks.json"></div><p>We can print the file content using <code>cat</code>, and then use <code>jq</code> to query the array items. </p><p><code>cat $bookmarksFile  | jq -r &#x27;.[]&#x27;</code></p><details><summary>Why I&#x27;m using a JSON file instead of a simple text file. Click here for the answer:</summary><p>It is because in the article <a href="../5-interactive-bookmarks-v2/5-interactive-bookmarks-v2.mdx">Interactive bookmarks menu v2</a> I will add new features with more advanced bookmarks 😁</p></details><h3>2. List the bookmarks</h3><p>Here is where <code>fzf</code> comes up. Anything that <code>fzf</code>  receives is listed interactively. In this case, we pipe the <code>jq</code> result to <code>fzf</code>, so the bookmarks are listed as shown in the <a href="#demo">demo</a> section.</p><p><code>cat $bookmarksFile | jq -r &#x27;.[]&#x27; | fzf</code></p><h3>3. Once a bookmark is selected, navigate to it</h3><p><code>fzf</code> returns the path selected, we save it to a variable.</p><p><code>local pathSelected=$(cat $bookmarksFile | jq -r &#x27;.[]&#x27; | fzf)</code></p><p>Last, we check if it is not empty (<code>-n</code>) before moving into:</p><pre><code class="language-bash">if [[ -n &quot;$pathSelected&quot; ]]; then
    cd $pathSelected
else
    echo &quot;no bookmark selected&quot;
fi
</code></pre><h2>Bonus: execute this every time you open a terminal</h2><p>You have to add this in your bash or zsh profile (<em>.bashrc</em>, <em>.zshrc</em> ). Just append the <code>listBookmarks</code> implementation at the end, update the <code>bookmarksFile</code> variable to be a full path, and call the function.</p><pre><code class="language-bash">listBookmarks() {
    local bookmarksFile=&#x27;YOUR_PATH/bookmarks.json&#x27;
    local pathSelected=$(cat $bookmarksFile |
        jq -r &#x27;.[]&#x27; |
        fzf)

    if [[ -n &quot;$pathSelected&quot; ]]; then
        cd $pathSelected
    else
        echo &quot;no bookmark selected&quot;
    fi
}

listBookmarks
</code></pre><p>And that is all! I hope this saves you some time using the terminal. Do you find this useful? Do you have similar functions? Let me know in the comments below.</p><div id="xUPOqo6E1XvWXwlCyQ"></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How to use the PowerShell Profile to be more productive]]></title>
            <link>https://cangulo.github.io/blog/ps-profile-productive</link>
            <guid>ps-profile-productive</guid>
            <pubDate>Mon, 24 Aug 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[In this post, I will explain how to set up shortcuts in the PowerShell Profile. Everything in this article works for PowerShell 5.1 and later.]]></description>
            <content:encoded><![CDATA[<p>In this post, I will explain how to set up shortcuts in the PowerShell Profile. Everything in this article works for PowerShell 5.1 and later.</p><p>If you are a PowerShell (a.k.a. PS) user, I&#x27;m sure at some point you repeat operations as navigating to a specific folder (e.g. your local GitHub repository). Maybe you run a script to clean or prepare your environment. Let&#x27;s define those two scenarios as next:</p><ol><li>Go to your local git repository folder.<ul><li>Code to execute: <code>cd .\source\repos\</code></li></ul></li><li>Execute a script.<ul><li>Code to execute: <code>$HOME\source\repos\TaskManager\startTaskManagerScript.ps1</code></li></ul></li></ol><h2>What is the PS Profile?</h2><p>The PS Profile is a script that is run when the console starts, setting custom user settings as variables, aliases or functions. We can also use it to execute custom commands to prepare our local environment. Check your <code>$Profile</code> variable to know where your profile is stored.</p><p><img src="./2020-08-26-configuring-powershell-profile/Profile-variable.png" alt="Profile variables"/></p><h2>Shortcuts</h2><p>The shortcuts we are going to set are functions or aliases depending on the following situations:</p><ol><li>For a command with static parameters, we will write functions. For example, <code>goToRepos</code> as a shortcut for <code>cd $HOME\source\repos</code>. The code will be:</li></ol><p><code>function NAME { COMMAND_WITH_PARAMS }</code> -&gt; <code>function goToRepos { cd $HOME\source\repos }</code></p><ol start="2"><li>We will define an alias for frequently used commands which we call with different parameters. For example, we use <code>Select-String</code> to filter file content as next:</li></ol><pre><code class="language-powershell">Select-String [-Pattern] PATTERN [-Path] PATH
</code></pre><p><img src="ss-executed.png"/></p><p>Instead of writing <code>Select-String</code>, we could write <code>ss</code>. Next is the alias:</p><p><code>New-Alias -Name ALIAS -Value COMMAND</code> -&gt; <code>New-Alias -Name ss -Value Select-String</code></p><p>In our case, we want to avoid typing the full <em>startTaskManagerScript</em>, so we set that path as COMMAND.</p><p><code>New-Alias -Name startTaskManagerAPI -Value $HOME\source\repos\TaskManager\startTaskManagerScript.ps1</code></p><h3>Creating the profile</h3><p>Let&#x27;s create and open the PS profile, execute the following command in PS: <code>code $PROFILE</code>, you should see the code editor empty. Considering that both commands share the <code>$HOME\source\repos</code> path, we could define a variable to short them as next:</p><pre><code class="language-powershell"># Variables

$localRepo = $HOME + &#x27;\source\repos&#x27;

# Functions

function goToRepos { cd $localRepo }

# Alias

New-Alias -Name startTaskManagerAPI -Value $localRepo\TaskManager\startTaskManagerScript.ps1
</code></pre><p>Please note the <code>$localrepo</code> variable will be available during the PS session. This means you can use it anytime, just as the variable <code>$HOME</code>. Paste the previous code into your profile and save it.</p><p>Open a new PS window. Maybe the next error will show up:</p><p><img src="./2020-08-26-configuring-powershell-profile/digitally-signed-problem.png" alt="Problem Signature Profile"/></p><p>That is because PS has an execution policy that only accepts signed scripts (<code>AllSigned</code>). We need to change it to <code>RemoteSigned</code> to verify the signature for remote scripts, but not locals. We have to do it using the following command:</p><p><code>Set-ExecutionPolicy RemoteSigned -Scope CurrentUser</code>. Now we are good to go, open a new PS and try to execute the shortcuts we defined. </p><p><img src="./2020-08-26-configuring-powershell-profile/shortcuts-execution.png" alt="Shortcuts execution"/></p><p>:::tip use the autocomplete feature!
You don&#x27;t need to write your aliases or functions completely. Just type the initial part and press <code>tab</code>.
:::</p><p>And we&#x27;re done! I hope this helps you to save time when using PS. Do you know any other tweak to be more productive? Feel free to share it in the comments!</p><h2>References</h2><ul><li><a href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_profiles?view=powershell-5.1">PowerShell Profiles Reference for PS 5.1</a></li><li><a href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_profiles?view=powershell-5.1#the-profile-files">Profiles Files in PS 5.1</a></li><li><a href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/set-alias?view=powershell-5.1#example-4--create-an-alias-to-an-executable-file">Example 4: Create an alias to an executable file</a></li><li><a href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/set-alias?view=powershell-5.1#example-4--create-an-alias-to-an-executable-file">Example 5: Create an alias for a command with parameters</a></li><li><a href="https://www.tenforums.com/general-support/107659-how-sign-powershell-profile-w-self-signed-certificate.html">How to sign PowerShell profile w/ self-signed certificate?</a></li><li><a href="https://www.hanselman.com/blog/SigningPowerShellScripts.aspx">Signing PowerShell Scripts</a></li></ul>]]></content:encoded>
        </item>
    </channel>
</rss>